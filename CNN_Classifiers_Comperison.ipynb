{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2392,"status":"ok","timestamp":1664356433959,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"HUL2bD6-TZAB","outputId":"e803d1ed-4640-4f78-e479-08e0c009e75b"},"outputs":[],"source":["!pip install tensorflow_addons\n","!pip install numpy\n","!pip install matplotlib\n","!pip install opencv-python\n","!pip install scipy\n","!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1664356433959,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"Jm8v5QZwTTAB"},"outputs":[],"source":["# basics\n","import numpy as np\n","import PIL.Image as Image\n","import os\n","import pathlib\n","import matplotlib.pylab as plt\n","import random\n","import cv2\n","import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras\n","import scipy\n","\n","# datageneraton\n","from keras.preprocessing.image import ImageDataGenerator\n","import tensorflow.keras.applications as applications\n","\n","# for new top layers\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout, Input\n","from tensorflow.keras.models import Model\n","\n","# hypeparameters\n","from tensorflow.keras.optimizers import Adam\n","from keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import TopKCategoricalAccuracy\n","from tensorflow_addons.metrics import F1Score\n","\n","# Callbacks\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# models\n","from tensorflow.keras.applications.nasnet import NASNetMobile\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n","from tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.xception import Xception\n","from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169"]},{"cell_type":"markdown","metadata":{"id":"fRHbSuMzWwdQ"},"source":["## Set Up"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1664356433959,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"M-ygYEldTc1p"},"outputs":[],"source":["WARM_UP_EPOCHS     = 10\n","FINE_TUNE_EPOCHS   = 25\n","BASE_LEARNING_RATE = 0.001\n","USE_EARLY_STOP     = False\n","DATA_DIRECTORY     = ''"]},{"cell_type":"markdown","metadata":{},"source":["### DataLoaders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1664356434403,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"FNseAKMJTegx","outputId":"84d83a3b-5b5c-42a2-f4dd-d78c77eadd71"},"outputs":[],"source":["def get_dataloaders(data_dir:str, batch_size:int, width, height:int, model_name:str):\n","    \"\"\"\n","    This function creates and returns the dataloaders for images using ImageDataGenerator from keras.\n","\n","    Parameters:\n","    :param data_dir:     A string representing the path to the data directory where the data is already\n","                         divided into 3 folders: train, val, and test.\n","    :param batch_size:   An integer representing the batch size for the dataloaders\n","    :param image_width:  An integer representing the width of the images, according to the pretrained\n","                         model's specifications.\n","    :param image_height: An integer representing the height of the images, according to the pretrained\n","                         model's specifications.\n","    :param model_name:   A string representing the name of the model to be used.\n","\n","    Returns:\n","    :return: train_loader, val_loader, test_loader\n","    \"\"\"\n","\n","    def __image_preprocess(image:np.array):\n","        \"\"\"\n","        Rescales an image to the specified width and height. If the model type is 'efficientnet',\n","        the image values are also rescaled to the range [0, 1].\n","        \n","        Parameters:\n","        :param image: The image to be preprocssed.\n","        \n","        Returns:\n","        :return: The preprocssed image.\n","        \"\"\"\n","\n","        size = (width, height)\n","\n","        if 'efficientnet' not in model_name.lower():\n","            # Normilize images - EfficientNets do not need normalization\n","            image = image/255.0 # rescale\n","        # Resizing\n","        image = cv2.resize(image,size)\n","\n","        return image\n","\n","    # Create a the training data generator (with augmentation methods)\n","    train_datagen = ImageDataGenerator(# Augmentation_methods\n","                                       rotation_range=10,       # rotate randomly for [0,10] degrees\n","                                       horizontal_flip=True,    # flip horizontally\n","                                       vertical_flip=True,      # flip vertically\n","                                       width_shift_range=0.05,  # shift in width dimention randomly for [0,5]%\n","                                       height_shift_range=0.05, # shift in height dimention randomly for [0,5]%\n","                                       brightness_range=[0.3,0.9],\n","                                       shear_range=0.1,         # shear randomly for [0,1]%\n","                                       zoom_range=0.2,          # zoom randomly for [0,2]%\n","                                       # Resizing\n","                                       preprocessing_function=__image_preprocess\n","                                       )\n","\n","    print('Train:\\t\\t', end='')\n","    # Load and iterate training dataset\n","    train_it = train_datagen.flow_from_directory(directory=data_dir + 'train',\n","                                                 target_size=(height, width),\n","                                                 class_mode='categorical',\n","                                                 batch_size=batch_size,\n","                                                 save_format='jpg'\n","                                                 )\n","\n","    # Create a the validation and test data generator\n","    test_datagen = ImageDataGenerator(preprocessing_function=__image_preprocess)\n","\n","    \n","    print('Validation:\\t', end='')\n","    # Load and iterate validation dataset\n","    val_it = test_datagen.flow_from_directory(directory=data_dir + 'val',\n","                                              target_size=(height, width),\n","                                              class_mode='categorical',\n","                                              batch_size=batch_size,\n","                                              save_format='jpg'\n","                                              )\n","\n","    print('Test:\\t\\t', end='')\n","    # Load and iterate test dataset\n","    test_it = test_datagen.flow_from_directory(directory=data_dir + 'test',\n","                                               target_size=(height, width),\n","                                               class_mode='categorical',\n","                                               batch_size=batch_size,\n","                                               save_format='jpg'\n","                                               )\n","\n","    return train_it, val_it, test_it"]},{"cell_type":"markdown","metadata":{"id":"t0U5RDPyVtf4"},"source":["### Weights (For Imbalanced Data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1664356434734,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"05dbIBEETinp","outputId":"2b67c9eb-29dc-46bc-9ef5-f03bc8d46aa6"},"outputs":[],"source":["def get_weights(data_dir:str, n_classes:int):\n","    \"\"\"\n","    Computes class weights for imbalanced data. The function counts the number of samples \n","    in each class in the training data and computes the weight for each class based on the \n","    total number of samples and the number of samples in each class.\n","    \n","    Parameters:\n","    :param data_dir:  The directory containing the training data.\n","    :param n_classes: The number of classes in the dataset.\n","    \n","    Returns:\n","    :return: A dictionary containing the class weights, where the keys are the class indices\n","             and the values are the computed weights.\n","    \"\"\"\n","\n","    # For imbalanced data \n","    samples_dict = dict()\n","    total_samples = 0\n","    dataset_dir = data_dir + 'train'\n","\n","    # Count each class population and the total sum\n","    for sub_folder in os.listdir(dataset_dir):\n","        sub_folder_dir = os.path.join(dataset_dir,sub_folder)\n","        sub_folder_count = len(os.listdir(sub_folder_dir))   \n","        samples_dict[sub_folder] = sub_folder_count\n","        total_samples += sub_folder_count\n","\n","    # Compute weights of each class\n","    class_weights = {}\n","\n","    for i in range(n_classes):\n","        w = total_samples / (n_classes * samples_dict[list(samples_dict.keys())[i]])\n","        class_weights[i] = w\n","\n","    return class_weights"]},{"cell_type":"markdown","metadata":{"id":"xpdAbHhOW2Lp"},"source":["### Early Stopping"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1664356434735,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"ZMIeOounTicZ"},"outputs":[],"source":["early_stop = EarlyStopping(monitor='val_loss',\n","                           mode='min',\n","                           verbose=1,\n","                           patience=5\n","                           )"]},{"cell_type":"markdown","metadata":{"id":"l_6qpH6aXAfY"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1664356434736,"user":{"displayName":"Giwrgos Terzoglou","userId":"11072311670215858616"},"user_tz":-180},"id":"iRt3Fo-9TiZz"},"outputs":[],"source":["# Define the list of models to compare\n","models = {'NASNetMobile'  : NASNetMobile,\n","          'VGG16'         : VGG16,\n","          'VGG19'         : VGG19,\n","          'ResNet50V2'    : ResNet50V2,\n","          'ResNet101V2'   : ResNet101V2,\n","          'ResNet152V2'   : ResNet152V2,\n","          'MobileNetV2'   : MobileNetV2,\n","          'InceptionV3'   : InceptionV3,\n","          'Xception'      : Xception,\n","          'DenseNet121'   : DenseNet121,\n","          'DenseNet169'   : DenseNet169,\n","          'EfficientNetB0': EfficientNetB0,\n","          'EfficientNetB1': EfficientNetB1,\n","          'EfficientNetB2': EfficientNetB2,\n","          'EfficientNetB3': EfficientNetB3,\n","          'EfficientNetB4': EfficientNetB4,\n","          'EfficientNetB5': EfficientNetB5,\n","          'EfficientNetB6': EfficientNetB6,\n","          'EfficientNetB7': EfficientNetB7\n","          }\n","\n","# Define the parameters of each model. Note that the batch size is calculated\n","# for my machine, in your case there may be a need to make some adjustments.\n","parameters =  {'NASNetMobile'  : {'input_sizes':(160, 120), 'batch_size':64},\n","               'VGG16'         : {'input_sizes':(160, 120), 'batch_size':64},\n","               'VGG19'         : {'input_sizes':(160, 120), 'batch_size':64},\n","               'ResNet50V2'    : {'input_sizes':(160, 120), 'batch_size':64},\n","               'ResNet101V2'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'ResNet152V2'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'MobileNetV2'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'InceptionV3'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'Xception'      : {'input_sizes':(160, 120), 'batch_size':64},\n","               'DenseNet121'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'DenseNet169'   : {'input_sizes':(160, 120), 'batch_size':64},\n","               'EfficientNetB0': {'input_sizes':(224, 224), 'batch_size':32},\n","               'EfficientNetB1': {'input_sizes':(240, 240), 'batch_size':32},\n","               'EfficientNetB2': {'input_sizes':(260, 260), 'batch_size':32},\n","               'EfficientNetB3': {'input_sizes':(300, 300), 'batch_size':16},\n","               'EfficientNetB4': {'input_sizes':(380, 380), 'batch_size':16},\n","               'EfficientNetB5': {'input_sizes':(456, 456), 'batch_size':16},\n","               'EfficientNetB6': {'input_sizes':(528, 528), 'batch_size':16},\n","               'EfficientNetB7': {'input_sizes':(600, 600), 'batch_size':16},\n","               } "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Chek if every model has a input size assigned\n","len(models.keys()) == len(parameters.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check if there is an available GPU\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VqD5nkCTiWx","outputId":"b0d395fc-a443-4795-df35-5014aca11fc1"},"outputs":[],"source":["history_warm_up     = {}\n","history_fine_tuning = {}\n","history_evaluation  = {}\n","\n","# Iterate through the models dictionary\n","for idx, model_name in enumerate(models.keys()):\n","    \n","    print(f'{model_name} {\"-\"*100}')\n","    \n","    # Get data in expecting shape\n","    (in_height, in_width, channels) = (parameters[model_name]['input_sizes'][0],parameters[model_name]['input_sizes'][1], 3)\n","    batch_size = parameters[model_name]['batch_size']\n","    \n","    print(f'Input tensor shape: ({in_height}, {in_width}, {channels})')\n","    train_it, val_it, test_it = get_dataloaders(DATA_DIRECTORY, batch_size, in_width, in_height, model_name)\n","    n_classes = train_it.num_classes\n","    print(f'Number of Classes: {n_classes}')\n","\n","    # Get weights\n","    class_weights = get_weights(DATA_DIRECTORY, n_classes)\n","\n","    # Call the model architexture\n","    model_class = models[model_name]\n","    # specify model parameters\n","    model = model_class(include_top=False,  # Do not include the first layer. This is necessary to change the input tensor size\n","                        weights='imagenet', # Pretraind weights from imagnet\n","                        input_tensor=Input(shape=(in_height, in_width, channels))\n","                        )\n","    \n","    # Freeze the model\n","    for layer in model.layers:\n","        layer.trainable = False\n","        \n","    # Add new layers at-the end\n","    x = Flatten()(model.output)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dropout(rate=0.2)(x)\n","    prediction = Dense(n_classes, activation='softmax')(x)\n","    \n","    # Define the new model\n","    model = Model(inputs=model.input, outputs=prediction)\n","    \n","    # Compile\n","    model.compile(optimizer = Adam(learning_rate=BASE_LEARNING_RATE),\n","                  loss = CategoricalCrossentropy(from_logits=True),\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    # Prepare Callbacks\n","    callbacks = []\n","    if USE_EARLY_STOP:\n","        callbacks.append(early_stop)\n","\n","    # Let's warm up the new layers!\n","    print('Training (Warm_Up):')\n","    history_warm_up[model_name] = model.fit(train_it,\n","                                            epochs=WARM_UP_EPOCHS,\n","                                            validation_data=(val_it),\n","                                            class_weight=class_weights,\n","                                            callbacks=callbacks,\n","                                            workers=-1,\n","                                            use_multiprocessing=True\n","                                           )\n","    \n","    # Un-freeze only the last layers witch compute more hight level features\n","    model.trainable = True\n","    print(\"Number of layers in the base model: \", len(model.layers))\n","    # Fine-tune from this layer onwards\n","    fine_tune_at = int(0.75 * len(model.layers)) # Note that the 0.75 isn't fixed\n","    print(f\"Fine-Tune from layer {fine_tune_at}\")\n","\n","    # Freeze all the layers before the `fine_tune_at` layer\n","    for layer in model.layers[:fine_tune_at]:\n","        layer.trainable = False\n","    \n","    # Compile\n","    model.compile(optimizer = Adam(learning_rate=BASE_LEARNING_RATE*0.1),\n","                  loss = CategoricalCrossentropy(from_logits=True),\n","                  metrics = ['accuracy']\n","                  )\n","\n","    total_epochs = WARM_UP_EPOCHS+FINE_TUNE_EPOCHS\n","\n","    # Let's fine tune it!\n","    print('Training (Fine_tune):')\n","    history_fine_tuning[model_name] = model.fit(train_it,\n","                                                epochs=total_epochs, # End epoch (including the previous training epochs)\n","                                                initial_epoch=WARM_UP_EPOCHS, # Continue from previous epoch\n","                                                validation_data=(val_it),\n","                                                class_weight=class_weights,\n","                                                callbacks=callbacks,\n","                                                workers=-1,\n","                                                use_multiprocessing=True\n","                                                )\n","    \n","    # Evaluation time!\n","    print('Evaluation:')\n","    history_evaluation[model_name] = model.evaluate(test_it,\n","                                                    workers=-1,\n","                                                    use_multiprocessing=True\n","                                                    )\n","    \n","    print()\n","    print() # NEXT!"]},{"cell_type":"markdown","metadata":{"id":"fFufyHUnXFSo"},"source":["## Results"]},{"cell_type":"markdown","metadata":{"id":"B_NEyuX5XIVQ"},"source":["### Training & Validation History"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def metric_history(model_name:str, metric:str):\n","    \"\"\"\n","    Retrieves the training history of a specific metric for a specific model.\n","    The history is retrieved from the warm-up phase and fine-tuning phase.\n","    The function concatenates the warm-up phase and fine-tuning phase history and returns them as a list.\n","    \n","    Parameters:\n","    :param model_name: The name of the model.\n","    :param metric: The name of the metric to retrieve the history of.\n","        \n","    Returns:\n","    :return: A list containing the history of the specified metric for the specified model.\n","    \"\"\"\n","    warm_up   = history_warm_up    [model_name].history[metric]\n","    fine_tune = history_fine_tuning[model_name].history[metric]\n","    \n","    return warm_up + fine_tune\n","    \n","\n","train_metrics = ['loss',     'accuracy'    ]\n","val_metrics   = ['val_loss', 'val_accuracy']\n","\n","plot_columns = int(len(train_metrics))\n","\n","# Iterate through the models dictionary\n","for idx, model_name in enumerate(list(models.keys())):\n","    print(model_name.upper(), ':')\n","    \n","    # Plot progression graphs\n","    plt.figure(figsize=(12,3))\n","    for i in range(plot_columns):\n","        plt.subplot(1, plot_columns, i + 1)\n","        plt.title((train_metrics[i].replace('_', ' ')).title())\n","        \n","        # Set axes\n","        if 'loss' not in train_metrics[i]:\n","            plt.ylim(0.0, 1.0)\n","        plt.xlim(0, total_epochs)\n","        plt.grid(axis='y', linestyle='-')\n","\n","        # Plots\n","        plt.plot(metric_history(model_name,train_metrics[i]))\n","        plt.plot(metric_history(model_name,val_metrics  [i]))\n","        vline_position = len(history_warm_up[model_name].history[train_metrics[i]])\n","        plt.axvline(x=vline_position, color='green', ls='--')\n","\n","        # Legent     \n","        plt.legend(['train', 'val', 'fine tune'], loc='best')\n","    \n","    plt.show()\n","\n","    print() # NEXT!"]},{"cell_type":"markdown","metadata":{"id":"4giPyBBnXLFo"},"source":["### Compare Evaluation metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WD8-h4ugTzah"},"outputs":[],"source":["# Create list for each metric\n","eval_loss = []\n","eval_acc  = []\n","\n","# Iterate through the evaluation history dictionary and\n","# extract the loss and accuracy values\n","for [loss, acc] in history_evaluation.values():\n","    eval_loss.append(loss)\n","    eval_acc.append(acc)\n","\n","labels = list(models.keys()) # List of model names\n","\n","x = np.arange(len(labels))  # The label locations\n","width = 0.30  # The width of the bars\n","\n","fig, ax = plt.subplots(figsize=(13, 7))\n","rects2 = ax.bar(x + 0.2, eval_acc, width, label='Accuracy')\n","\n","# Add some text for labels, title and custom x-axis tick labels, etc.\n","ax.set_ylabel('Scores')\n","ax.set_title('Scores by Model', fontsize=22)\n","ax.set_xticks(x, labels, rotation = 90, fontsize=14)\n","ax.legend(loc=\"best\", fontsize=12)\n","\n","# Add the label value on each bar\n","ax.bar_label(rects2, fmt='%.2f', fontsize=12)\n","\n","fig.tight_layout(rect=(0,0,1.2,1.1))\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMQpq7WAs3+/16EMweiPBKq","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('PVGnosis_tensorflow')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"e685cd98153e43b51851aafface5bab024c73456e237dfd581745851655cb2fa"}}},"nbformat":4,"nbformat_minor":0}
